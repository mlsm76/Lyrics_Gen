{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mitch\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import keras\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = open(\"Lyrics_Counterparts.txt\", encoding=\"utf-8\").read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 5, 8, 9, 3]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47   70652\n"
     ]
    }
   ],
   "source": [
    "max_id = len(tokenizer.word_index) #number of distinct characters in text\n",
    "dataset_size = tokenizer.document_count #total number of characters\n",
    "print(max_id, \" \", dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([lyrics])) - 1\n",
    "#encodes the full text so each character is represented by its ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset for training/test/validation\n",
    "train_size = dataset_size * 90//100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert long string of characters into windows for training(batches)\n",
    "n_steps = 100\n",
    "window_length = n_steps + 1 #target character = input shifted 1 char ahead\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the dataset for training\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "#this gives us a single tensor for each window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1984/1984 [==============================] - 2148s 1s/step - loss: 2.3424\n",
      "Epoch 2/50\n",
      "1984/1984 [==============================] - 2034s 1s/step - loss: 1.5608\n",
      "Epoch 3/50\n",
      "1984/1984 [==============================] - 2058s 1s/step - loss: 1.4299\n",
      "Epoch 4/50\n",
      "1984/1984 [==============================] - 2044s 1s/step - loss: 1.3675\n",
      "Epoch 5/50\n",
      "1984/1984 [==============================] - 2135s 1s/step - loss: 1.3339\n",
      "Epoch 6/50\n",
      "1984/1984 [==============================] - 2063s 1s/step - loss: 1.3091\n",
      "Epoch 7/50\n",
      "1984/1984 [==============================] - 2053s 1s/step - loss: 1.2917\n",
      "Epoch 8/50\n",
      "1984/1984 [==============================] - 2058s 1s/step - loss: 1.2779\n",
      "Epoch 9/50\n",
      "1984/1984 [==============================] - 2054s 1s/step - loss: 1.2656\n",
      "Epoch 10/50\n",
      "1984/1984 [==============================] - 2055s 1s/step - loss: 1.2563\n",
      "Epoch 11/50\n",
      "1984/1984 [==============================] - 2066s 1s/step - loss: 1.2491\n",
      "Epoch 12/50\n",
      "1984/1984 [==============================] - 2059s 1s/step - loss: 1.2418\n",
      "Epoch 13/50\n",
      "1984/1984 [==============================] - 2058s 1s/step - loss: 1.2347\n",
      "Epoch 14/50\n",
      "1984/1984 [==============================] - 2057s 1s/step - loss: 1.2292\n",
      "Epoch 15/50\n",
      "1984/1984 [==============================] - 2055s 1s/step - loss: 1.2244\n",
      "Epoch 16/50\n",
      "1984/1984 [==============================] - 2075s 1s/step - loss: 1.2202\n",
      "Epoch 17/50\n",
      "1984/1984 [==============================] - 2062s 1s/step - loss: 1.2152\n",
      "Epoch 18/50\n",
      "1984/1984 [==============================] - 2060s 1s/step - loss: 1.2089\n",
      "Epoch 19/50\n",
      "1984/1984 [==============================] - 2061s 1s/step - loss: 1.2056\n",
      "Epoch 20/50\n",
      "1984/1984 [==============================] - 2063s 1s/step - loss: 1.2035\n",
      "Epoch 21/50\n",
      "1984/1984 [==============================] - 2058s 1s/step - loss: 1.2005\n",
      "Epoch 22/50\n",
      "1984/1984 [==============================] - 2274s 1s/step - loss: 1.1965\n",
      "Epoch 23/50\n",
      "1984/1984 [==============================] - 2190s 1s/step - loss: 1.1953\n",
      "Epoch 24/50\n",
      "1984/1984 [==============================] - 2058s 1s/step - loss: 1.1912\n",
      "Epoch 25/50\n",
      "1984/1984 [==============================] - 2072s 1s/step - loss: 1.1897\n",
      "Epoch 26/50\n",
      "1984/1984 [==============================] - 2036s 1s/step - loss: 1.1863\n",
      "Epoch 27/50\n",
      "1984/1984 [==============================] - 2039s 1s/step - loss: 1.1837\n",
      "Epoch 28/50\n",
      "1984/1984 [==============================] - 2042s 1s/step - loss: 1.1808\n",
      "Epoch 29/50\n",
      "1984/1984 [==============================] - 2059s 1s/step - loss: 1.1787\n",
      "Epoch 30/50\n",
      "1984/1984 [==============================] - 2042s 1s/step - loss: 1.1764\n",
      "Epoch 31/50\n",
      "1984/1984 [==============================] - 2036s 1s/step - loss: 1.1744\n",
      "Epoch 32/50\n",
      "1984/1984 [==============================] - 2036s 1s/step - loss: 1.1722\n",
      "Epoch 33/50\n",
      "1984/1984 [==============================] - 2058s 1s/step - loss: 1.1695\n",
      "Epoch 34/50\n",
      "1984/1984 [==============================] - 2058s 1s/step - loss: 1.1680\n",
      "Epoch 35/50\n",
      "1984/1984 [==============================] - 2031s 1s/step - loss: 1.1674\n",
      "Epoch 36/50\n",
      "1984/1984 [==============================] - 2034s 1s/step - loss: 1.1651\n",
      "Epoch 37/50\n",
      "1984/1984 [==============================] - 2048s 1s/step - loss: 1.1632\n",
      "Epoch 38/50\n",
      "1984/1984 [==============================] - 2036s 1s/step - loss: 1.1618\n",
      "Epoch 39/50\n",
      "1984/1984 [==============================] - 2035s 1s/step - loss: 1.1616\n",
      "Epoch 40/50\n",
      "1984/1984 [==============================] - 2038s 1s/step - loss: 1.1598\n",
      "Epoch 41/50\n",
      "1984/1984 [==============================] - 2066s 1s/step - loss: 1.1573\n",
      "Epoch 42/50\n",
      "1984/1984 [==============================] - 2097s 1s/step - loss: 1.1548\n",
      "Epoch 43/50\n",
      "1984/1984 [==============================] - 2054s 1s/step - loss: 1.1559\n",
      "Epoch 44/50\n",
      "1984/1984 [==============================] - 2071s 1s/step - loss: 1.1537\n",
      "Epoch 45/50\n",
      "1984/1984 [==============================] - 2059s 1s/step - loss: 1.1514\n",
      "Epoch 46/50\n",
      "1984/1984 [==============================] - 2056s 1s/step - loss: 1.1508\n",
      "Epoch 47/50\n",
      "1984/1984 [==============================] - 2058s 1s/step - loss: 1.1474\n",
      "Epoch 48/50\n",
      "1984/1984 [==============================] - 2074s 1s/step - loss: 1.1485\n",
      "Epoch 49/50\n",
      "1984/1984 [==============================] - 2065s 1s/step - loss: 1.1480\n",
      "Epoch 50/50\n",
      "1984/1984 [==============================] - 2073s 1s/step - loss: 1.1445\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                    dropout=0.3, recurrent_dropout=0.2),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, \n",
    "                     dropout=0.3, recurrent_dropout=0.2),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, \n",
    "                     dropout=0.3, recurrent_dropout=0.2),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, \n",
    "                     dropout=0.3, recurrent_dropout=0.2),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id,\n",
    "                                                   activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('char_rnn_lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new,steps=1)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba)/ temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "#this function picks the next character randomly, with a probability equal to the estimated probability,using tf.random.categorical\n",
    "#categorical() samples random class indices, given the class probs (logits)\n",
    "#temperature is a variables that controls the diversity of the characters generated\n",
    "# a near-zero temperature will output characters with high probabilities\n",
    "# a high temperature will give all characters equal probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function repeatedly calls the above function to generate text\n",
    "def complete_text(text, n_chars=100, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char (text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mind they have burdened\n",
      "we will be remembered\n",
      "we will be remembered\n",
      "we will be remembered\n",
      "we will be inth back of alive\n",
      "and i wonâ€™t life is your feeling there is right? \n",
      "and i am an outcast\n",
      "i am not leated than expression\n",
      "\n",
      "existence so this words lie to shake a north the blight of open arms\n",
      "though i facan fame we're never being them\n",
      "and while i made we are left to relect from the tells\n",
      "that we've beenhe existence of crashing to be\n",
      "and i will never being think\n",
      "i reject me far anyone close words\n",
      "but i \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"m\",temperature=1)+ complete_text(\"i\",temperature=1)+ complete_text(\"t\",temperature=1)+complete_text(\"c\",temperature=1)+complete_text(\"h\",temperature=1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.repeat().window(window_length, shift=n_steps, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.repeat().batch(1)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                    dropout=0.3, recurrent_dropout=0.3, batch_input_shape=[batch_size, None, max_id]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                    dropout=0.3, recurrent_dropout=0.3),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                    dropout=0.3, recurrent_dropout=0.3),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     dropout=0.3, recurrent_dropout=0.3),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id,\n",
    "                                                   activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "steps_per_epoch = train_size // batch_size // n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 22s 906ms/step - loss: 3.5794\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 18s 964ms/step - loss: 3.0053\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 18s 950ms/step - loss: 2.9800\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 18s 944ms/step - loss: 2.9741\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 2.9711\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 2.9586\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 2.9077\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 2.8445\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 2.7682\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 2.6967\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 2.6279\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 2.5652\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 2.5167\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 2.4674\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 18s 945ms/step - loss: 2.4284\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 2.3857\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 2.3549\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 19s 987ms/step - loss: 2.3166\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 2.2805\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 2.2562\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 18s 948ms/step - loss: 2.2259\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 2.2018\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 2.1812\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 18s 963ms/step - loss: 2.1625\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 2.1429\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 2.1256\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 2.1096\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 2.0931\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 18s 947ms/step - loss: 2.0807\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 2.0571\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 2.0500\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 18s 950ms/step - loss: 2.0422\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 2.0328\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 2.0134\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 2.0015\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 2.0024\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 18s 952ms/step - loss: 1.9783\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 18s 968ms/step - loss: 1.9698\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 18s 950ms/step - loss: 1.9600\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 18s 944ms/step - loss: 1.9582\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 18s 940ms/step - loss: 1.9476\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.9377\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 18s 940ms/step - loss: 1.9321\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 18s 940ms/step - loss: 1.9222\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.9189\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 18s 923ms/step - loss: 1.9057\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 18s 951ms/step - loss: 1.9053\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.8934\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.8874\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.8818\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 18s 945ms/step - loss: 1.8686\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.8625\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.8661\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.8562\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 18s 951ms/step - loss: 1.8487\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.8440\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 17s 916ms/step - loss: 1.8385\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 18s 949ms/step - loss: 1.8355\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.8241\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.8259\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.8115\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.8112\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.8058\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 18s 920ms/step - loss: 1.8088\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 18s 923ms/step - loss: 1.8025\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 18s 944ms/step - loss: 1.7987\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 18s 922ms/step - loss: 1.7948\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.7911\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.7748\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 18s 938ms/step - loss: 1.7761\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.7707\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.7645\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.7639\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.7548\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.7568\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.7544\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 18s 952ms/step - loss: 1.7425\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.7433\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 18s 922ms/step - loss: 1.7393\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.7336\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 18s 944ms/step - loss: 1.7344\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.7367\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 18s 938ms/step - loss: 1.7229\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 18s 938ms/step - loss: 1.7204\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.7259\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.7181\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.7181\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 19s 979ms/step - loss: 1.7143\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.7110\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.7004\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.7027\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 18s 940ms/step - loss: 1.6973\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.6907\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.6866\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.6871\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.6858\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.6788\n",
      "Epoch 98/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 18s 926ms/step - loss: 1.6805\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 18s 947ms/step - loss: 1.6761\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.6780\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.6782\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 18s 955ms/step - loss: 1.6632\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 19s 1s/step - loss: 1.6736\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 1.6586\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.6594\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.6572\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.6570\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.6528\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.6527\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 18s 952ms/step - loss: 1.6552\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.6527\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.6405\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.6449\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 18s 945ms/step - loss: 1.6423\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.6344\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.6383\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.6264\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 18s 945ms/step - loss: 1.6345\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 19s 981ms/step - loss: 1.6351\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 18s 954ms/step - loss: 1.6339\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 18s 946ms/step - loss: 1.6294\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 18s 947ms/step - loss: 1.6239\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.6275\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.6186\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 18s 944ms/step - loss: 1.6147\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.6165\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.6134\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 18s 947ms/step - loss: 1.6167\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 1.6130\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.6110\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.6027\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.6011\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 18s 938ms/step - loss: 1.6057\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 1.6005\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.5995\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 18s 964ms/step - loss: 1.6010\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.5896\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 18s 965ms/step - loss: 1.5946\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 18s 966ms/step - loss: 1.5952\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 19s 985ms/step - loss: 1.5805\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.5923\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 18s 940ms/step - loss: 1.5835\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.5860\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 18s 943ms/step - loss: 1.5782\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.5834\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.5837\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 18s 952ms/step - loss: 1.5785\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 18s 957ms/step - loss: 1.5754\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 18s 963ms/step - loss: 1.5805\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 18s 950ms/step - loss: 1.5700\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.5822\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.5800\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 18s 944ms/step - loss: 1.5673\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 18s 953ms/step - loss: 1.5627\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.5710\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.5667\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.5653\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 18s 948ms/step - loss: 1.5643\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 1.5699\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.5591\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.5608\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 18s 944ms/step - loss: 1.5556\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 18s 951ms/step - loss: 1.5523\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 18s 948ms/step - loss: 1.5591\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 18s 954ms/step - loss: 1.5513\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.5588\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 18s 947ms/step - loss: 1.5462\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.5488\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 18s 950ms/step - loss: 1.5389\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.5412\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.5458\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 18s 945ms/step - loss: 1.5548\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 18s 950ms/step - loss: 1.5481\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 18s 938ms/step - loss: 1.5411\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 1.5465\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.5428\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 18s 946ms/step - loss: 1.5404\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 18s 962ms/step - loss: 1.5424\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.5418\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 18s 945ms/step - loss: 1.5364\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.5408\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 18s 943ms/step - loss: 1.5352\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 20s 1s/step - loss: 1.5329\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 18s 961ms/step - loss: 1.5378\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.5286\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.5297\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 18s 958ms/step - loss: 1.5270\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.5231\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 18s 969ms/step - loss: 1.5298\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.5374\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 18s 948ms/step - loss: 1.5265\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 20s 1s/step - loss: 1.5267\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 19s 971ms/step - loss: 1.5203\n",
      "Epoch 194/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 18s 938ms/step - loss: 1.5195\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 18s 951ms/step - loss: 1.5195\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.5226\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.5202\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 18s 961ms/step - loss: 1.5245\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.5127\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.5226\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.5120\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 18s 949ms/step - loss: 1.5201\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.5135\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 19s 997ms/step - loss: 1.5088\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.5090\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 18s 951ms/step - loss: 1.5164\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.5103\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.5117\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 18s 950ms/step - loss: 1.5079\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 1.5088\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 18s 953ms/step - loss: 1.5112\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.5148\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.5109\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 18s 945ms/step - loss: 1.5016\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 18s 947ms/step - loss: 1.5052\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 18s 964ms/step - loss: 1.5087\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.5117\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 18s 949ms/step - loss: 1.5048\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 18s 946ms/step - loss: 1.5050\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 19s 989ms/step - loss: 1.5019\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.5008\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.4976\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 18s 948ms/step - loss: 1.4985\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4955\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4988\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4993\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.5007\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 18s 945ms/step - loss: 1.4988\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4916\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4865\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.4979\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.4913\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.5025\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.4985\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4868\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 18s 946ms/step - loss: 1.4908\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4953\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4947\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 18s 969ms/step - loss: 1.4938\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 18s 938ms/step - loss: 1.4850\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 18s 920ms/step - loss: 1.4839\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 18s 950ms/step - loss: 1.4889\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.4853\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 18s 920ms/step - loss: 1.4893\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 18s 949ms/step - loss: 1.4830\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.4812\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4835\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4801\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 18s 951ms/step - loss: 1.4824\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 1.4787\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.4816\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.4822\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4746\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 18s 944ms/step - loss: 1.4735\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 18s 923ms/step - loss: 1.4746\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4764\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.4794\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4795\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 1.4733\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.4757\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4832\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.4712\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 17s 922ms/step - loss: 1.4733\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4699\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4666\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 17s 918ms/step - loss: 1.4701\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.4658\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 18s 938ms/step - loss: 1.4693\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.4778\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 18s 923ms/step - loss: 1.4735\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.4790\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.4747\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4639\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4686\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4648\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.4627\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4628\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 17s 915ms/step - loss: 1.4693\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.4719\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 18s 921ms/step - loss: 1.4680\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 17s 920ms/step - loss: 1.4642\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 18s 920ms/step - loss: 1.4641\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 18s 946ms/step - loss: 1.4588\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.4556\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 17s 919ms/step - loss: 1.4596\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4593\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.4619\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 18s 964ms/step - loss: 1.4641\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 18s 922ms/step - loss: 1.4617\n",
      "Epoch 290/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 18s 958ms/step - loss: 1.4616\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.4609\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4588\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 17s 922ms/step - loss: 1.4653\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4607\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 17s 917ms/step - loss: 1.4529\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4579\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 17s 911ms/step - loss: 1.4535\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 18s 940ms/step - loss: 1.4516\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 17s 914ms/step - loss: 1.4569\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4496\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 18s 938ms/step - loss: 1.4500\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.4551\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 17s 919ms/step - loss: 1.4488\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 18s 923ms/step - loss: 1.4571\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4499\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 19s 989ms/step - loss: 1.4479\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 17s 914ms/step - loss: 1.4547\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 1.4573\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.4539\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4549\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 17s 914ms/step - loss: 1.4598\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 17s 920ms/step - loss: 1.4500\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 18s 946ms/step - loss: 1.4501\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 1.4510\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 17s 911ms/step - loss: 1.4383\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4501\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.4477\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4439\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 18s 921ms/step - loss: 1.4499\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.4546\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 1.4401\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 18s 969ms/step - loss: 1.4444\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 17s 920ms/step - loss: 1.4402\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.4512\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 1.4472\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 17s 919ms/step - loss: 1.4400\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4477\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4500\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 17s 916ms/step - loss: 1.4388\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4445\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4434\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4421\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 17s 918ms/step - loss: 1.4453\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 17s 917ms/step - loss: 1.4382\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 1.4428\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 17s 918ms/step - loss: 1.4434\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 1.4435\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4346\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.4446\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 18s 951ms/step - loss: 1.4424\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 18s 966ms/step - loss: 1.4357\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 18s 963ms/step - loss: 1.4385\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.4224\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.4312\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 18s 920ms/step - loss: 1.4330\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4440\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.4391\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 17s 910ms/step - loss: 1.4380\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4381\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.4408\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 18s 946ms/step - loss: 1.4305\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4394\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 17s 923ms/step - loss: 1.4363\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4291\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 17s 915ms/step - loss: 1.4366\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 1.4387\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.4368\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 18s 944ms/step - loss: 1.4312\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 17s 912ms/step - loss: 1.4384\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4359\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 18s 939ms/step - loss: 1.4299\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4323\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4291\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 17s 922ms/step - loss: 1.4283\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.4266\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4287\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 18s 921ms/step - loss: 1.4327\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4260\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.4272\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 17s 913ms/step - loss: 1.4397\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 18s 922ms/step - loss: 1.4327\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4366\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.4342\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.4210\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 17s 920ms/step - loss: 1.4335\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 18s 943ms/step - loss: 1.4245\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 18s 921ms/step - loss: 1.4236\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 17s 917ms/step - loss: 1.4254\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 17s 916ms/step - loss: 1.4243\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 1.4247\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.4266\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 18s 953ms/step - loss: 1.4300\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 18s 938ms/step - loss: 1.4193\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4224\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.4290\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 18s 943ms/step - loss: 1.4189\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 18s 954ms/step - loss: 1.4266\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4208\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.4271\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.4266\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 18s 957ms/step - loss: 1.4205\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.4237\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4181\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4179\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4312\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 17s 914ms/step - loss: 1.4291\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4213\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4159\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4228\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 17s 913ms/step - loss: 1.4128\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 17s 918ms/step - loss: 1.4213\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 1.4204\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4180\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 17s 917ms/step - loss: 1.4194\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 17s 909ms/step - loss: 1.4134\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.4211\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 17s 917ms/step - loss: 1.4190\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 19s 978ms/step - loss: 1.4243\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 1.4222\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4181\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4122\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 17s 922ms/step - loss: 1.4136\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 1.4112\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.4240\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 17s 923ms/step - loss: 1.4152\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 18s 922ms/step - loss: 1.4125\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 1.4099\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 17s 913ms/step - loss: 1.4171\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4182\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 18s 956ms/step - loss: 1.4126\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 18s 970ms/step - loss: 1.4208\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 19s 975ms/step - loss: 1.4139\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 18s 967ms/step - loss: 1.4086\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 19s 986ms/step - loss: 1.4168\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 19s 999ms/step - loss: 1.4122\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 18s 967ms/step - loss: 1.4230\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 19s 987ms/step - loss: 1.4175\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 19s 985ms/step - loss: 1.4186\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 18s 965ms/step - loss: 1.4185\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 18s 968ms/step - loss: 1.4142\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 19s 978ms/step - loss: 1.4046\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 19s 979ms/step - loss: 1.4104\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 18s 947ms/step - loss: 1.4117\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 18s 922ms/step - loss: 1.4102\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.4147\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 19s 987ms/step - loss: 1.4201\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 18s 956ms/step - loss: 1.4135\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 18s 955ms/step - loss: 1.4060\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 18s 922ms/step - loss: 1.4074\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 18s 940ms/step - loss: 1.4159\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 17s 917ms/step - loss: 1.4093\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 18s 958ms/step - loss: 1.4072\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 18s 948ms/step - loss: 1.4143\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 1.4139\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4131\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.4156\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4096\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 18s 923ms/step - loss: 1.4105\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 18s 935ms/step - loss: 1.4063\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.4102\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4027\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 18s 940ms/step - loss: 1.4058\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 18s 953ms/step - loss: 1.4069\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 18s 934ms/step - loss: 1.4019\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4159\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 17s 914ms/step - loss: 1.4094\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 18s 932ms/step - loss: 1.4022\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 18s 923ms/step - loss: 1.4074\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 18s 920ms/step - loss: 1.4008\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 17s 918ms/step - loss: 1.4068\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 18s 946ms/step - loss: 1.4113\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 17s 919ms/step - loss: 1.4032\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4010\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.4106\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 18s 936ms/step - loss: 1.3978\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 18s 923ms/step - loss: 1.4045\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 17s 918ms/step - loss: 1.4069\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4038\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 18s 933ms/step - loss: 1.4053\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 18s 929ms/step - loss: 1.4105\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 18s 930ms/step - loss: 1.4070\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 18s 937ms/step - loss: 1.4006\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 17s 917ms/step - loss: 1.4000\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 1.4013\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 18s 925ms/step - loss: 1.3948\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.4013\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 18s 964ms/step - loss: 1.4001\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 18s 953ms/step - loss: 1.3977\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 1.4005\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.3894\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 18s 923ms/step - loss: 1.4034\n",
      "Epoch 482/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 17s 914ms/step - loss: 1.4017\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 18s 941ms/step - loss: 1.4034\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 18s 922ms/step - loss: 1.4028\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 18s 919ms/step - loss: 1.3999\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 1.3993\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 18s 940ms/step - loss: 1.4018\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.4008\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 17s 920ms/step - loss: 1.3968\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.4001\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 18s 928ms/step - loss: 1.3915\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 17s 916ms/step - loss: 1.4007\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 1.4076\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 18s 926ms/step - loss: 1.3872\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 18s 927ms/step - loss: 1.3932\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 17s 921ms/step - loss: 1.3985\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 17s 918ms/step - loss: 1.4021\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.4008\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 18s 924ms/step - loss: 1.3892\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 17s 916ms/step - loss: 1.3950\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=500, callbacks=[ResetStatesCallback()], steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('stateful_rnn_lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stateless copy to allow us to use different batch sizes\n",
    "stateless_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.build(tf.TensorShape([None, None, max_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.set_weights(model.get_weights())\n",
    "model = stateless_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tions starm\n",
      "if wonâ€™t left to finden un a sleaved world\n",
      "is all to you canâ€™t exmecting the untray\n",
      "to sk\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ming for a share that but to leave\n",
      "not what i know where i'm remembered in nothing\n",
      "\n",
      "man if i am\n",
      "promiing the insidence\n",
      "decenting shearting in the rest back\n",
      "our part\n",
      "befring my heart both sleep the gracets carry of an used of wastes myself coure\n",
      "so i am the gracious bfoint of the nust become those will ce on the thurs this alses of my mind\n",
      "be searching the world failly greave\n",
      "our lost in the composen bher in the stay\n",
      "not know into myself direcussed that's we draved\n",
      "drown ins alone of this\n",
      "\n",
      "\n",
      "sports you\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"m\")+ complete_text(\"i\")+ complete_text(\"t\")+complete_text(\"c\")+complete_text(\"h\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
